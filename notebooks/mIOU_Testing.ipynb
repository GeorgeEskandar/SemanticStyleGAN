{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usrhomes/g013/anaconda3/envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "from imageio import imread\n",
    "from scipy import linalg\n",
    "import argparse\n",
    "import sys\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "sys.path.insert(0, \"../../SemanticStyleGAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Segmenter output and Our Model's output to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_down_mapping_v2 = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "    4: 0,\n",
    "    5: 0,\n",
    "    6: 0,\n",
    "    7: 1,\n",
    "    8: 2,\n",
    "    9: 1,\n",
    "    10: 1,\n",
    "    11: 3,\n",
    "    12: 4,\n",
    "    13: 5,\n",
    "    14: 4,\n",
    "    15: 3,\n",
    "    16: 3,\n",
    "    17: 6,\n",
    "    18: 6,\n",
    "    19: 7,\n",
    "    20: 8,\n",
    "    21: 9,\n",
    "    22: 9,\n",
    "    23: 10,\n",
    "    24: 11,\n",
    "    25: 12,\n",
    "    26: 13,\n",
    "    27: 14,\n",
    "    28: 14,\n",
    "    29: 14,\n",
    "    30: 14,\n",
    "    31: 14,\n",
    "    32: 15,\n",
    "    33: 15,\n",
    "}\n",
    "\n",
    "def simplify_image_labels(image,viewable=False):\n",
    "    new_image = np.zeros(image.shape)\n",
    "    for k, v in cut_down_mapping_v2.items():\n",
    "        mask = image == k\n",
    "        new_image[mask] =  v if not viewable else  ((v)*255)/15\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(img_list):\n",
    "    for i,img in enumerate(img_list):\n",
    "        if len(img )==3:\n",
    "            img = img.permute(1,2,0)\n",
    "        img = img.squeeze(0)\n",
    "        if(torch.is_tensor(img)):\n",
    "             img = (img).numpy()\n",
    "        cv2.imwrite(f\"./data/sample_image_testing_{i}.png\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSG_output=\"./data/our_model_output.npy\"\n",
    "segmenter_output=\"./data/segmentation_model_output_semanticp.npy\"\n",
    "#segmenter_output=\"./data/segmentation_model_output_SSG.npy\"\n",
    "img_dir= \"./data/real_segmentation_input.npy\"\n",
    "\n",
    "\n",
    "ssg=torch.from_numpy(np.load(SSG_output))\n",
    "segmentor = torch.from_numpy(np.load(segmenter_output))\n",
    "real_img = torch.from_numpy(np.load(img_dir))\n",
    "\n",
    "ssg_converted= (ssg*255)/15 ## Our SSG model segmentation output\n",
    "sem_index_pred = segmentor.max(dim=1, keepdim=True)[1] ##\n",
    "sem_converted= simplify_image_labels(sem_index_pred,False) ## The SEgmenter segmentation\n",
    "\n",
    "#Print Which Type Of Images\n",
    "#save_images(ssg_converted)\n",
    "#save_images(sem_converted)\n",
    "#save_images(real_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssg.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Model Input for segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_paletter_segmentation_input = \"./data/segmentation_model_input_semanticp.npy\"\n",
    "ssg_segmentation_input= \"./data/segmentation_model_input_SSG.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_seg_input=torch.from_numpy(np.load(semantic_paletter_segmentation_input))\n",
    "ssg_seg_input=torch.from_numpy(np.load(ssg_segmentation_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_seg_input.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(255.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssg_seg_input.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding was that segmentation pallete input range is from [-1 to 1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8daaeadef7a295f68d0e95189507333c5c96e909e217a26b6b4a4818e648299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
