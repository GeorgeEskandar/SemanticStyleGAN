{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import collections\n",
    "import re \n",
    "from imageio import imread, imwrite\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import gdown\n",
    "import math\n",
    "\n",
    "import shutil\n",
    "import imageio\n",
    "import time\n",
    "import torch\n",
    "#import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, \"../../SemanticStyleGAN\")\n",
    "from models import make_model\n",
    "from visualize.utils import generate,generate_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    0: [0, 0, 0], #Void\n",
    "    1: [128, 64,128], #Road\n",
    "    2: [220, 20, 60], # Human\n",
    "    3: [ 0,  0,142], # Vehicle\n",
    "    4: [70, 70, 70], # Buildings/Construction\n",
    "    5: [190,153,153],#Objects\n",
    "    6: [107,142, 35],# Naturer\n",
    "    7: [70,130,180], #Sky\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2image(tensor):\n",
    "    images = tensor.cpu().clamp(-1,1).permute(0,2,3,1).numpy()\n",
    "    images = images * 127.5 + 127.5\n",
    "    images = images.astype(np.uint8)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_images_segmentation(sample_img,sample_seg):\n",
    "    image = tensor2image(sample_img)\n",
    "    seg_dim = sample_seg.size(1)\n",
    "    sample_seg = torch.argmax(sample_seg, dim=1).detach().cpu().numpy()\n",
    "    split_masks=[]\n",
    "    split_images=[]\n",
    "    for key in range(seg_dim):\n",
    "        divided_image = np.zeros(image.shape)\n",
    "        sample_mask = np.zeros((sample_seg.shape[0], sample_seg.shape[1], sample_seg.shape[2], 3), dtype=np.uint8)\n",
    "        sample_mask[sample_seg==key] = color_map[key]\n",
    "        divided_image[sample_seg==key]=image[sample_seg==key]\n",
    "        #divided_image[np.isin(sample_seg,[key,4])]=image[np.isin(sample_seg,[key,4])] #For Several classes\n",
    "        split_masks.append(sample_mask)\n",
    "        split_images.append(divided_image)\n",
    "    return split_masks,split_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(ckpt_loc,truncation_mean=10000,batch=8,truncation=0.7,device=\"cuda\",sample=3,outdir=\"./data/multiple_d\"):\n",
    "    ckpt = torch.load(ckpt_loc)\n",
    "    model = make_model(ckpt[\"args\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    model.load_state_dict(ckpt[\"g_ema\"])\n",
    "    mean_latent = model.style(\n",
    "        torch.randn(truncation_mean, model.style_dim, device=device)\n",
    "    ).mean(0)\n",
    "    print(\"Generating images ...\")\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        styles = model.style(\n",
    "            torch.randn(sample, model.style_dim, device=device)\n",
    "        )\n",
    "        styles = truncation * styles + (\n",
    "            1 - truncation\n",
    "        ) * mean_latent.unsqueeze(0)\n",
    "        # images, segs = generate(\n",
    "        #     model, styles, mean_latent=mean_latent, batch_size=batch\n",
    "        # )\n",
    "\n",
    "        images, segs,images_tensor,segs_tensor = generate_tensors(\n",
    "            model, styles, mean_latent=mean_latent, batch_size=batch\n",
    "        )\n",
    "        seg_splits,images_splits=split_images_segmentation(images_tensor,segs_tensor)\n",
    "        for i in range(len(images)):\n",
    "            imageio.imwrite(f\"{outdir}/{str(i).zfill(6)}_img_mul_dis.png\", images[i])\n",
    "            imageio.imwrite(f\"{outdir}/{str(i).zfill(6)}_seg_mul_dis.png\", segs[i])\n",
    "            for j in range(len(seg_splits)):\n",
    "                imageio.imwrite(f\"{outdir}/{str(i).zfill(6)}_seg_mul_dis_{j}.png\", seg_splits[j][i])\n",
    "                imageio.imwrite(f\"{outdir}/{str(i).zfill(6)}_img_mul_dis_{j}.png\", images_splits[j][i])\n",
    "        return images, segs,images_tensor,segs_tensor\n",
    "            # if save_latent:\n",
    "            #     np.save(\n",
    "            #         f\"{outdir}/{str(i).zfill(6)}_latent.npy\",\n",
    "            #         styles[i : i + 1].cpu().numpy(),\n",
    "            #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model with arguments:\n",
      "{'aug': False,\n",
      " 'base_layers': 2,\n",
      " 'batch': 4,\n",
      " 'channel_multiplier': 2,\n",
      " 'checkpoint_dir': '/usr/stud/faragy/storage/user/data/checkpoints/SSG_v2.2',\n",
      " 'ckpt': '/usr/stud/faragy/storage/user/data/checkpoints/SSG_v2.2/ckpt/185000.pt',\n",
      " 'coarse_channel': 512,\n",
      " 'coarse_size': 64,\n",
      " 'd_reg_every': 16,\n",
      " 'dataset': '/usr/stud/faragy/storage/user/data/lmdb_datasets/lmdb_v2.2',\n",
      " 'depth_layers': 6,\n",
      " 'detach_texture': False,\n",
      " 'distributed': False,\n",
      " 'g_reg_every': 4,\n",
      " 'inception': '/usr/stud/faragy/storage/user/data/inception_models/inception_v2.2.pkl',\n",
      " 'iter': 600001,\n",
      " 'lambda_mask': 100.0,\n",
      " 'latent': 512,\n",
      " 'local_channel': 64,\n",
      " 'local_layers': 10,\n",
      " 'local_rank': 0,\n",
      " 'lr': 0.002,\n",
      " 'min_feat_size': 16,\n",
      " 'mixing': 0.3,\n",
      " 'n_gpu': 1,\n",
      " 'n_mlp': 8,\n",
      " 'n_sample': 16,\n",
      " 'num_workers': 8,\n",
      " 'path_batch_shrink': 2,\n",
      " 'path_regularize': 0.5,\n",
      " 'r1_img': 10,\n",
      " 'r1_seg': 1000,\n",
      " 'residual_refine': True,\n",
      " 'save_every': 5000,\n",
      " 'seg_dim': 8,\n",
      " 'size': 256,\n",
      " 'start_iter': 185000,\n",
      " 'transparent_dims': (10, 12),\n",
      " 'viz_every': 2000}\n",
      "n_latent: 18, n_latent_expand: 80\n",
      "Generating images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 230.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 249.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 246.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 234.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 248.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 253.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 221.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 175.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 107.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 155.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "ckpt_loc=\"/usr/stud/faragy/storage/user/data/checkpoints/SSG_v2.2/ckpt/380000.pt\" #Using the 8 LGs to test\n",
    "images, segs,images_tensor,segs_tensor=generate_images(ckpt_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_splits[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seg_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 186.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 243.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 245.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 127.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "#create 1 image for each segmentation class out of result\n",
    "seg_splits,images_splits=split_images_segmentation(segs_tensor,images_tensor)\n",
    "outdir = \"./data/multiple_d\"\n",
    "for i in range(len(seg_splits)):\n",
    "    imageio.imwrite(f\"{outdir}/{str(0).zfill(6)}_seg_mul_dis_{i}.png\", seg_splits[i][0])\n",
    "    imageio.imwrite(f\"{outdir}/{str(0).zfill(6)}_img_mul_dis_{i}.png\", images_splits[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 256, 256, 3)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_splits[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seg_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
